{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb49f925-7056-4a77-a632-f19d22e9b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from hyperopt import tpe,fmin,Trials,hp,rand,anneal,space_eval\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 统计notavailable的情况\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.rcParams['font.sans-serif']=['SimHei']   # 用黑体显示中文\n",
    "plt.rcParams['axes.unicode_minus']=False  \n",
    "import seaborn as sns\n",
    "# 使用LightGBM进行模型预训练，并检测异常值\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158f3ee4-cd59-4a2f-9271-6f139eb59704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face_x', 'faces_y', 'face_size', 'h3', 's3', 'v3', '333', 'product_category1', 'product_category2'] 被删除\n",
      "(7835, 535)\n",
      "(2000, 535)\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv(\"train_all_features_noPCA-2.csv\",index_col=0)\n",
    "\n",
    "test=pd.read_csv(\"test_all_features_noPCA-2.csv\",index_col=0)\n",
    "def onehot(name,train=train,test=test):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    clf=OneHotEncoder(sparse=False)\n",
    "    clf.fit(train.loc[:,name].to_numpy().reshape(-1,1))\n",
    "    res_train=clf.transform(train.loc[:,name].to_numpy().reshape(-1,1))   \n",
    "    res_test=clf.transform(test.loc[:,name].to_numpy().reshape(-1,1))\n",
    "    new_columns=[name+str(i) for i in range(0,res_train.shape[1])]\n",
    "    train.loc[:,new_columns]=res_train\n",
    "    test.loc[:,new_columns]=res_test\n",
    "    train=train.drop(name,axis=1)\n",
    "    test=test.drop(name,axis=1)\n",
    "    return (train,test)\n",
    "def drop_multiline(train,test):\n",
    "    \"\"\"删掉强相关变量\"\"\"\n",
    "    train_corr=train.corr()\n",
    "    test_corr=test.corr()\n",
    "    be_droped=[];\n",
    "    for i,index in enumerate(train_corr.index):\n",
    "        for j,column in enumerate(train_corr.columns):\n",
    "            if  column not in be_droped and i<j and train_corr.loc[index,column]>0.9 and test_corr.loc[index,column]>0.9:\n",
    "                train=train.drop(column,axis=1)\n",
    "                test=test.drop(column,axis=1)\n",
    "                # print(column,\"被删除\")\n",
    "                be_droped.append(column)\n",
    "                # return drop_multiline(train,test)\n",
    "    print(be_droped,\"被删除\")\n",
    "    return (train,test)\n",
    "\n",
    "train,test=onehot(\"brand\")\n",
    "train,test=onehot(\"product_category\")\n",
    "# test=test.dropna()\n",
    "train,test=drop_multiline(train,test)\n",
    "X_columns=np.array([i for i in train.columns[:] \n",
    "                    if i!=\"product_id\" and i!=\"price\" and i!=\"face_x\" and i!=\"faces_y\" and i!=\"face_size\" ])\n",
    "X_train=train.loc[:,X_columns].to_numpy()\n",
    "X_test=test.loc[:,X_columns].to_numpy()\n",
    "y_train=train.loc[:,\"price\"].to_numpy()\n",
    "y_test=test.loc[:,\"price\"].to_numpy()\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d898e6-dd91-414d-abd2-237f2294feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(object):\n",
    "    \"\"\"定义一个Machine的类。\n",
    "    本Machine类的思路如下：\n",
    "    任何一个特殊的模型如SVC都可以用来建立Machine类\n",
    "    通过调用self.headquater方法可以完成从hyperopt参数寻优一直到模型报告的过程\n",
    "    如果想象征性的跑一跑代码看看能不能跑通，把HyperoptTrain(self,max_evals=50)中的50改为较小的数字即可（比如3）\"\"\"\n",
    "    def __init__(self,clf,params:dict,\n",
    "                 X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    "        self.X_test=X_test\n",
    "        self.y_test=y_test\n",
    "        self.clf=clf\n",
    "        self.params=params\n",
    "    def Report(self):\n",
    "        \"\"\"报告分类性能的函数,同时画出分类结果ROC函数\"\"\"\n",
    "        y_train_predict=self.clf.predict(self.X_train)\n",
    "        y_predict=self.clf.predict(self.X_test)\n",
    "        train_mae=mean_absolute_error(y_true=self.y_train,y_pred=y_train_predict)\n",
    "        train_mse=mean_squared_error(y_true=self.y_train,y_pred=y_train_predict)\n",
    "        train_r2=r2_score(y_true=self.y_train,y_pred=y_train_predict)\n",
    "        test_mae=mean_absolute_error(y_true=self.y_test,y_pred=y_predict)\n",
    "        test_mse=mean_squared_error(y_true=self.y_test,y_pred=y_predict)\n",
    "        test_r2=r2_score(y_true=self.y_test,y_pred=y_predict)\n",
    "        \n",
    "        print(\"=\"*60)    \n",
    "        print(\"train数据集上模型精度指标(MAE,MSE,R2):\",[train_mae,train_mse,train_r2])\n",
    "        print(\"test数据集上模型精度指标(MAE,MSE,R2):\",[test_mae,test_mse,test_r2])\n",
    "        print(\"=\"*60)    \n",
    "    def objective(self,params):\n",
    "        self.clf.set_params(**params)\n",
    "        self.clf.fit(self.X_train,self.y_train)\n",
    "        y_pred=self.clf.predict(self.X_test)\n",
    "        res=r2_score(y_true=self.y_test,y_pred=y_pred)\n",
    "        return -res\n",
    "    def HyperoptTrain(self,max_evals=50):\n",
    "        \"\"\"使用tpe.suggest寻找最优参数\"\"\"\n",
    "        trials=Trials()\n",
    "        if self.model_name!=\"SVR\" and self.model_name!=\"Isotonic\":\n",
    "            self.params[\"random_state\"]=hp.choice(\"random_state\",[0]) #加一个random_state操作\n",
    "        best_params=fmin(fn=self.objective,space=self.params,\n",
    "                         algo=tpe.suggest,max_evals=max_evals,trials=trials)\n",
    "        best_params=space_eval(self.params, best_params)\n",
    "        # np.save(file_path+self.model_name+\"best_params\",best_params)\n",
    "        print(\"best params:\\n\",best_params)\n",
    "        self.clf.set_params(**best_params)\n",
    "        self.clf.fit(self.X_train,self.y_train)\n",
    "        return self.clf\n",
    "    def headquarter(self,model_name,max_evals=50):\n",
    "        \"\"\"中心调度器，完成从模型训练直到模型报告的所有工作\"\"\"\n",
    "        self.model_name=model_name\n",
    "        self.clf=self.HyperoptTrain(max_evals)\n",
    "        print(model_name,\"模型\",\"训练完成，下面是模型报告：\")\n",
    "        self.Report()\n",
    "        return self.clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2b68c8-c78d-482a-8a92-eb93757b8fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 150/150 [06:49<00:00,  2.73s/trial, best loss: -0.04538051103088703]\n",
      "best params:\n",
      " {'boosting_type': 'gbdt', 'learning_rate': 0.21000000000000002, 'max_depth': 3, 'min_split_gain': 0.05420612259948168, 'n_estimators': 30, 'num_leaves': 60, 'random_state': 0, 'reg_alpha': 0.8659578194486246, 'reg_lambda': 0.04989104834225522}\n",
      "LGBM 模型 训练完成，下面是模型报告：\n",
      "============================================================\n",
      "train数据集上模型精度指标(MAE,MSE,R2): [1280.3183371330729, 20227337.771141175, 0.4852873616890675]\n",
      "test数据集上模型精度指标(MAE,MSE,R2): [1795.8083622930308, 217559320.245632, 0.04538051103088703]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "clf_LGBM=LGBMRegressor()\n",
    "params_LGBM={\n",
    "        \"boosting_type\":hp.choice(\"boosting_type\",[\"gbdt\"]),\n",
    "        'max_depth': hp.choice('max_depth', [0,1,2,3]),\n",
    "        'num_leaves':  hp.choice('num_leaves', np.arange(50,150,10, dtype=int)),\n",
    "        'learning_rate': hp.choice('learning_rate',np.arange(0.01,0.5,0.01)),\n",
    "        'n_estimators': hp.choice(\"n_estimators\",np.arange(10,150,10,dtype=int)),\n",
    "        \"min_split_gain\":hp.uniform(\"min_split_gain\",0,0.08),\n",
    "        \"reg_alpha\":hp.uniform(\"reg_alpha\",0.01,1),\n",
    "        \"reg_lambda\": hp.uniform(\"reg_lambda\",0.01,1)\n",
    "    }\n",
    "\n",
    "LGBM_machine=Machine(clf_LGBM,params_LGBM,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test)\n",
    "clf_LGBM=LGBM_machine.headquarter(model_name=\"LGBM\",max_evals=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3da4ad-3e03-4a8a-bdf7-7adef80fdc86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重要性: [13  6  6  5  5  5  4  4  4  4  4  4  4  3  3  3  3  3  3  3  3  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0]\n",
      "特征名称： ['favorite' 'negative_info' '281' '93' '376' '229' 'h1' '107' '168' '489'\n",
      " 's2' 'brand' 'quantity' '375' '364' '455' '321' '392' '85' '195' '60'\n",
      " '131' '332' 'brand1' '54' '25' '360' '144' '462' '28' '306' 's1' '356'\n",
      " '52' '81' '243' '42' '207' '423' '387' '358' '417' '411' '363' '77' '394'\n",
      " '87' '104' '110' '108' '120' '106' '382' '422' '138' '121' '174' '220'\n",
      " '239' '213' '208' '206' '199' '198' '258' '259' '196' '184' '177' '176'\n",
      " '284' '347' '172' '298' '160' '156' '151' '310' '313' '320' '324' '133'\n",
      " '129' '340' '343' '432' '373' '434' '472' '452' '457' '41' '459' '448'\n",
      " '488' '445' '444' '12' '13' 'text_regions' '503' '26' 'v2' '475' '511'\n",
      " '474' 'coner_numbers' '19' '149' '170' '165' '166' '167' '145' '169'\n",
      " '171' '143' '163' '20' '11' '173' '10' '9' '175' '21' '164' '147' '146'\n",
      " '155' '18' '17' '16' '152' '153' '15' '154' '14' '150' '157' '7' '148'\n",
      " '158' '159' '161' '162' '8' '180' '6' '178' '203' '204' '205' 'v1' 'h2'\n",
      " '209' '210' 'contour_numbers' '211' '212' 'keypoint' '214' '215' '216'\n",
      " '217' '218' '219' 'face_numbers' '221' '222' '223' '202' '201' '200'\n",
      " '188' '179' '141' '181' '182' '183' '5' '185' '186' '187' '189' '197'\n",
      " '190' '191' '192' '193' '194' '4' '3' '2' '1' '142' '136' '22' '140' '76'\n",
      " '47' '78' '79' '80' '46' '82' '83' '84' '45' '86' '88' '44' '89' '90'\n",
      " '91' '92' '43' '94' '95' '96' '75' '74' '73' '63' '56' '57' '58' '59'\n",
      " '53' '61' '62' '51' '50' '64' '72' '65' '66' '49' '67' '68' '69' '70'\n",
      " '71' '48' '97' '98' '99' '127' '31' '30' '122' '29' '123' '124' '125'\n",
      " '27' '126' '128' '118' '130' '24' '132' '134' '135' '55' '137' '23' '139'\n",
      " '119' '117' '100' '109' '101' '40' '102' '225' '103' '39' '105' '38' '37'\n",
      " '36' '116' '35' '111' '112' '34' '113' '33' '114' '32' '115' '224'\n",
      " 'product_category0' '226' '227' '409' '410' '412' '413' '414' '415' '416'\n",
      " '418' '419' '420' '421' '424' '425' '426' '427' '428' '429' '430' '431'\n",
      " '433' '435' '436' '437' '438' '439' '440' '441' '408' '407' '406' '389'\n",
      " '372' '374' '377' '378' '379' '380' '381' '383' '384' '385' '386' '388'\n",
      " '390' '405' '391' '393' '395' '396' '397' '398' '399' '400' '401' '402'\n",
      " '403' '404' '442' '443' '446' '501' '487' '490' '491' '492' '493' '494'\n",
      " '495' '496' '497' '498' '499' '500' '502' '485' '504' '505' '506' '507'\n",
      " '508' '509' '510' '512' 'brand0' 'brand2' 'brand3' 'brand4' '486' '484'\n",
      " '447' '466' '449' '450' '451' '453' '454' '456' '458' '460' '461' '463'\n",
      " '464' '465' '467' '483' '468' '469' '470' '471' '473' '476' '477' '478'\n",
      " '479' '480' '481' '482' '371' '370' '369' '275' '263' '264' '265' '266'\n",
      " '267' '268' '269' '270' '271' '272' '273' '274' '276' '261' '277' '278'\n",
      " '279' '280' '282' '283' '285' '286' '287' '288' '289' '290' '262' '260'\n",
      " '292' '242' '228' '230' '231' '232' '233' '234' '235' '236' '237' '238'\n",
      " '240' '241' '244' '257' '245' '246' '247' '248' '249' '250' '251'\n",
      " 'brand5' '253' '254' '255' '256' '291' '293' '368' '349' '334' '335'\n",
      " '336' '337' '338' '339' '341' '342' '344' '345' '346' '348' '350' '330'\n",
      " '351' '352' '353' '354' '355' '357' '359' '361' '362' '365' '366' '367'\n",
      " '331' '329' '294' '309' '295' '296' '297' '299' '300' '301' '302' '303'\n",
      " '304' '305' '307' '308' '311' '328' '312' '314' '315' '316' '317' '318'\n",
      " '319' '322' '323' '325' '326' '327' '252']\n"
     ]
    }
   ],
   "source": [
    "feature_importance=clf_LGBM.feature_importances_\n",
    "sort_index=np.argsort(feature_importance)\n",
    "print(\"重要性:\",feature_importance[sort_index[::-1]])\n",
    "print(\"特征名称：\",X_columns[sort_index[::-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fb4f7c-24f9-4280-8700-c684e019f26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "离群点个数： 477 389\n",
      "3397.724838944403 1725.027650835941\n",
      "(6844, 533) (6844,) (1795, 533) (1795,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "clf=LocalOutlierFactor(n_neighbors=20,novelty=True)\n",
    "clf.fit(feature_importance*X_train)\n",
    "outliers=clf.predict(feature_importance*X_train)\n",
    "outliers_test=clf.predict(feature_importance*X_test)\n",
    "print(\"离群点个数：\",len(outliers[outliers==-1]),len(outliers_test[outliers_test==-1]))\n",
    "print(np.mean(y_train[outliers==-1]),np.mean(y_train[outliers!=-1]))\n",
    "y_train_no_outlier=y_train[outliers!=-1]\n",
    "X_train_no_outlier=X_train[outliers!=-1]\n",
    "X_test_no_outlier=X_test[outliers_test!=-1]\n",
    "y_test_no_outlier=y_test[outliers_test!=-1]\n",
    "X_train_no_outlier=X_train_no_outlier[y_train_no_outlier<np.mean(y_train[outliers==-1]),:]\n",
    "y_train_no_outlier=y_train_no_outlier[y_train_no_outlier<np.mean(y_train[outliers==-1])]\n",
    "X_test_no_outlier=X_test_no_outlier[y_test_no_outlier<np.mean(y_train[outliers==-1]),:]\n",
    "y_test_no_outlier=y_test_no_outlier[y_test_no_outlier<np.mean(y_train[outliers==-1])]\n",
    "X_train_no_outlier=np.append(X_train_no_outlier,X_train[outliers==-1],axis=0)\n",
    "y_train_no_outlier=np.append(y_train_no_outlier,y_train[outliers==-1])\n",
    "X_test_no_outlier=np.append(X_test_no_outlier,X_test[outliers_test==-1],axis=0)\n",
    "y_test_no_outlier=np.append(y_test_no_outlier,y_test[outliers_test==-1])\n",
    "print(X_train_no_outlier.shape,y_train_no_outlier.shape,X_test_no_outlier.shape,y_test_no_outlier.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf72a12-20f0-4180-96e3-9960e48d2b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7835, 537) (2000, 537)\n",
      "(6844, 516) (1795, 516)\n"
     ]
    }
   ],
   "source": [
    "data_last=pd.read_csv(\"train_all_features_noPCA-2.csv\")\n",
    "test_last=pd.read_csv(\"test_all_features_noPCA-2.csv\")\n",
    "print(data_last.shape,test_last.shape)\n",
    "be_droped=['face_x', 'faces_y', 'face_size', 'h3', 's3', 'v3', '67', '88', '133','158', '218', '278',\n",
    "           '366', '400', '416', '452', '484', '314', '478', '433', '475']\n",
    "for i in be_droped:\n",
    "    data_last=data_last.drop(i,axis=1)\n",
    "    test_last=test_last.drop(i,axis=1)\n",
    "data_last_no_outlier=data_last.loc[outliers!=-1,:].copy()\n",
    "data_last_no_outlier=data_last_no_outlier.loc[data_last_no_outlier.loc[:,\"price\"]<np.mean(data_last.loc[outliers==-1,\"price\"]),:]\n",
    "data_last_no_outlier=data_last_no_outlier.append(data_last.loc[outliers==-1,:])\n",
    "test_last_no_outlier=test_last.loc[outliers_test!=-1,:].copy()\n",
    "test_last_no_outlier=test_last_no_outlier.loc[test_last_no_outlier.loc[:,\"price\"]<np.mean(data_last.loc[outliers==-1,\"price\"]),:]\n",
    "test_last_no_outlier=test_last_no_outlier.append(test_last.loc[outliers_test==-1,:])\n",
    "print(data_last_no_outlier.shape,test_last_no_outlier.shape)\n",
    "data_last_no_outlier.to_csv(\"train_all_features_noPCA-3.csv\",index=False)\n",
    "test_last_no_outlier.to_csv(\"test_all_features_noPCA-3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea7956-2dbd-4031-bbd8-0361e9d6ce69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
