{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "矩阵运算过分复杂，因此使用numpy现成的矩阵进行基本运算操作\n",
    "\"\"\"\n",
    "#下面是一些必要函数\n",
    "def f(x,U,Theta,V):\n",
    "    #f(x)函数的实现\n",
    "    return 1/2*abs(vnorm2(U*Theta*V*x-b))**2\n",
    "def vnorm2(x):\n",
    "    \"\"\"\n",
    "    返回numpy数组的二范数\n",
    "    \"\"\"\n",
    "    a=x.T*x\n",
    "    return a.tolist()[0][0]**(1/2)\n",
    "def btls(U,Theta,V,b,epsilon,x,s0,alpha,beta):\n",
    "    \"\"\"\n",
    "    backtracking line search,返回st\n",
    "    \"\"\"\n",
    "    k=0\n",
    "    s=s0\n",
    "    gradfx=V.T*Theta*Theta*V*x-V.T*Theta*U.T*b\n",
    "    while f(x-s*gradfx,U,Theta,V)>f(x,U,Theta,V)-alpha*s*(vnorm2(gradfx)**2) :\n",
    "        s=beta*s\n",
    "        k=k+1\n",
    "    return s\n",
    "def GD(U,Theta,V,b,epsilon,x0,isbtls):\n",
    "    \"\"\"\n",
    "    梯度下降法计算，\n",
    "    如果isbtls==1, 则使用btls函数进行回退法搜索合适的st,\n",
    "    否则使用beta函数\n",
    "    \"\"\"\n",
    "    t=0\n",
    "    tmax=10**30\n",
    "    print(\"设定可以容忍的最大迭代次数:\",tmax)\n",
    "    A=U*Theta*V\n",
    "    betabeta=max(np.linalg.eig(A.T*A)[0])\n",
    "    \"\"\"\n",
    "    beta方法的beta,是矩阵类型\n",
    "    \"\"\"\n",
    "    s0=100\n",
    "    st=s0\n",
    "    print(\"默认s0是:\",s0)\n",
    "    alpha=0.5\n",
    "    beta=0.5\n",
    "    if isbtls==1:\n",
    "        print(\"默认回退法的α是：\",alpha)\n",
    "        print(\"默认回退法的β是：\",beta)\n",
    "    xt=x0\n",
    "    gradfx=V.T*Theta*Theta*V*xt-V.T*Theta*U.T*b\n",
    "    chazhi_xt=abs(st*vnorm2(gradfx))\n",
    "    chazhi_fx=abs(alpha*st*vnorm2(gradfx)**2)\n",
    "    while t<tmax and chazhi_xt>=epsilon and chazhi_fx>epsilon and vnorm2(gradfx)>epsilon:\n",
    "        if isbtls==1:\n",
    "            st=btls(U,Theta,V,b,epsilon,xt,s0,alpha,beta)\n",
    "        else:\n",
    "            st=1/betabeta\n",
    "        xt1=xt-st*gradfx\n",
    "        chazhi_xt=abs(vnorm2(st*gradfx))\n",
    "        chazhi_fx=abs(f(xt1,U,Theta,V)-f(xt,U,Theta,V))\n",
    "        gradfx=V.T*Theta*Theta*V*xt1-V.T*Theta*U.T*b\n",
    "        xt=xt1\n",
    "        t=t+1\n",
    "    print(\"结果是：\")\n",
    "    print(xt)\n",
    "    r=Rr(U,Theta,V,b,xt)\n",
    "    return {\"迭代次数\":t,\"相对残差:\":r}\n",
    "def Rr(U,Theta,V,b,x):\n",
    "    \"\"\"\n",
    "    计算最后结果的相对残差：norm(b-A*x)/norm(b)\n",
    "    \"\"\"\n",
    "    A=U*Theta*V\n",
    "    Rr=vnorm2(b-A*x)/vnorm2(b)\n",
    "    return Rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "误差选取： 1e-08\n",
      "初值选取： [[0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#这是一系列初始化过程\n",
    "U=np.mat(\"-0.91,0.37,-0.18;0.19,0.78,0.59;0.36,0.50,-0.78\")\n",
    "Theta=np.mat([[3,0,0],[0,2,0],[0,0,1]])\n",
    "V=np.mat([[0.25,-0.73,-0.62],[-0.74,-0.56,0.35],[-0.61,0.37,-0.69]])\n",
    "b=np.mat([-0.29,-2.09,-0.98]).T\n",
    "epsilon=10**(-8)\n",
    "print(\"误差选取：\",epsilon)\n",
    "x0=np.mat([0,0,0]).T\n",
    "print(\"初值选取：\",x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是使用回退法求解第一种情况：\n",
      "设定可以容忍的最大迭代次数: 1000000000000000000000000000000\n",
      "默认s0是: 100\n",
      "默认回退法的α是： 0.5\n",
      "默认回退法的β是： 0.5\n",
      "结果是：\n",
      "[[ 1.04442925]\n",
      " [ 0.6147337 ]\n",
      " [-0.01459384]]\n",
      "回退法相对残差、迭代次数及时间: {'迭代次数': 17, '相对残差:': 0.013008213687960317}\n",
      "Wall time: 63 ms\n",
      "这是使用β法求解第一种情况：\n",
      "设定可以容忍的最大迭代次数: 1000000000000000000000000000000\n",
      "默认s0是: 100\n",
      "结果是：\n",
      "[[ 1.05223192]\n",
      " [ 0.5915582 ]\n",
      " [-0.01093355]]\n",
      "β法结相对残差、迭代次数及时间： {'迭代次数': 50, '相对残差:': 0.011823177272296592}\n",
      "Wall time: 15 ms\n",
      "这是使用回退法求解第二种情况：\n",
      "设定可以容忍的最大迭代次数: 1000000000000000000000000000000\n",
      "默认s0是: 100\n",
      "默认回退法的α是： 0.5\n",
      "默认回退法的β是： 0.5\n",
      "结果是：\n",
      "[[ 0.79076079]\n",
      " [ 0.74915293]\n",
      " [-0.28764644]]\n",
      "回退法相对残差、迭代次数及时间: {'迭代次数': 5, '相对残差:': 0.17811617184547832}\n",
      "Wall time: 32 ms\n",
      "这是使用β法求解第二种情况：\n",
      "设定可以容忍的最大迭代次数: 1000000000000000000000000000000\n",
      "默认s0是: 100\n",
      "结果是：\n",
      "[[ 24.67089074]\n",
      " [-13.95897883]\n",
      " [ 26.64480228]]\n",
      "β法结相对残差、迭代次数及时间： {'迭代次数': 232516, '相对残差:': 0.017281133278757316}\n",
      "Wall time: 59 s\n",
      "这是使用回退法求解第三种情况：\n",
      "设定可以容忍的最大迭代次数: 1000000000000000000000000000000\n",
      "默认s0是: 100\n",
      "默认回退法的α是： 0.5\n",
      "默认回退法的β是： 0.5\n",
      "结果是：\n",
      "[[ 0.78902485]\n",
      " [ 0.750218  ]\n",
      " [-0.28960461]]\n",
      "回退法相对残差、迭代次数及时间: {'迭代次数': 5, '相对残差:': 0.17814488504840534}\n",
      "Wall time: 18 ms\n",
      "这是使用β法求解第三种情况：\n",
      "设定可以容忍的最大迭代次数: 1000000000000000000000000000000\n",
      "默认s0是: 100\n",
      "结果是：\n",
      "[[ 0.79765405]\n",
      " [ 0.74839193]\n",
      " [-0.29824612]]\n",
      "β法相对残差、迭代次数及时间： {'迭代次数': 25, '相对残差:': 0.17798270465908833}\n",
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\"\"\"\n",
    "利用time函数来进行计时\n",
    "\"\"\"\n",
    "print(\"这是使用回退法求解第一种情况：\")\n",
    "%time print(\"回退法相对残差、迭代次数及时间:\",GD(U,Theta,V,b,epsilon,x0,1))\n",
    "print(\"这是使用β法求解第一种情况：\")\n",
    "%time print(\"β法结相对残差、迭代次数及时间：\",GD(U,Theta,V,b,epsilon,x0,0))\n",
    "Theta1=np.mat([[3,0,0],[0,2,0],[0,0,10**(-2)]])\n",
    "Theta2=np.mat([[3,0,0],[0,2,0],[0,0,10**(-6)]])\n",
    "print(\"这是使用回退法求解第二种情况：\")\n",
    "%time print(\"回退法相对残差、迭代次数及时间:\",GD(U,Theta1,V,b,epsilon,x0,1))\n",
    "print(\"这是使用β法求解第二种情况：\")\n",
    "%time print(\"β法结相对残差、迭代次数及时间：\",GD(U,Theta1,V,b,epsilon,x0,0))\n",
    "print(\"这是使用回退法求解第三种情况：\")\n",
    "%time print(\"回退法相对残差、迭代次数及时间:\",GD(U,Theta2,V,b,epsilon,x0,1))\n",
    "print(\"这是使用β法求解第三种情况：\")\n",
    "%time print(\"β法相对残差、迭代次数及时间：\",GD(U,Theta2,V,b,epsilon,x0,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
