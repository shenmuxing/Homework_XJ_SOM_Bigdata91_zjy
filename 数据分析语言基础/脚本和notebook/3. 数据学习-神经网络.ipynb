{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # 说明\n"," * 本notebook配置如下\n","     * python；3.7.0\n","     * torch:1.10.1"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch import optim\n","from torch.utils.data import Dataset\n","import torch.nn as nn\n","from 处理文件 import Process_data\n","from hyperopt import tpe,fmin,Trials,hp,rand,anneal,space_eval\n","file_path=\"../latex/tex/figures/\""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["正在处理: Beijing-result-2022-06-21.csv\n"," 正在删除强相关变量...\n","  删除前: (26204, 95)\n"," 删除完成 (26204, 90)\n","请核对训练集，测试集形状:\n","X_train.shape: (19653, 88)\n","y_train.shape: (19653,)\n","X_test.shape: (6551, 88)\n","y_test.shape: (6551,)\n"]}],"source":["res=Process_data(\"Beijing-result-2022-06-21.csv\")\n","X_columns=res[\"X_columns\"]\n","X_train,X_test,y_train,y_test=res[\"X_train\"],res[\"X_test\"],res[\"y_train\"],res[\"y_test\"]\n","y_train=y_train.to_numpy()\n","y_test=y_test.to_numpy()\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## 定义模型"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class MyDNN(nn.Module):\n","    def __init__(self,num_features,hidden1=56,hidden2=20):\n","        super().__init__()\n","        self.hidden1=nn.Linear(num_features,hidden1)\n","        self.hidden2=nn.Linear(hidden1,hidden2)\n","        self.output=nn.Linear(hidden2,1)\n","        self.activation=nn.ReLU()\n","    def forward(self,x):\n","        x=self.hidden1(x)\n","        x=self.activation(x)\n","        x=self.hidden2(x)\n","        x=self.activation(x)\n","        x=self.output(x)\n","        output=x\n","        return output\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# 定义损失函数\n","# 由于是回归任务，使用经典的MESLoss\n","\"\"\"\n","定义r2_loss\n","From https://en.wikipedia.org/wiki/Coefficient_of_determination\n","\"\"\"\n","def r2_loss(output, target):\n","    \"\"\"这个越大越好\"\"\"\n","    target_mean = torch.mean(target)\n","    ss_tot = torch.sum((target - target_mean) ** 2)\n","    # print(ss_tot)\n","    ss_res = torch.sum((target - output) ** 2)\n","    # print(ss_res)\n","    r2 = 1 - ss_res / ss_tot\n","    # print(\"ss_tot,ss_res,r2:\",ss_tot,ss_res,r2)\n","    return r2\n","#也有nn.L1Loss\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# 定义Loader,因为这里数据量较小，一个batch定义为1000\n","class MyDataset(Dataset):\n","    def __init__(self,X,y):\n","        self.X=torch.tensor(X).float()\n","        if type(y)==np.ndarray:\n","            self.y=torch.tensor(y.reshape(len(y),1)).float()\n","        else:\n","            self.y=torch.tensor(y.to_numpy().reshape(len(y),1)).float()\n","    def __len__(self):\n","        return len(self.y)\n","    def __getitem__(self,idx):\n","        return self.X[idx],self.y[idx]\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class Machine(object):\n","    \"\"\"定义一个Machine的类，和前面3.数据学习的思路是一致的，只是是专门为神经网络设计。\n","    如果想象征性的跑一跑代码看看能不能跑通，把HyperoptTrain(self,max_evals=50)中的50改为较小的数字即可（比如3）\"\"\"\n","    def __init__(self,params:dict,\n","                 X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n","        self.X_train=X_train\n","        self.y_train=y_train\n","        self.X_test=X_test\n","        self.y_test=y_test\n","        self.params=params\n","        self.criterion=nn.MSELoss()\n","    def Report(self):\n","        \"\"\"报告分类性能的函数,同时画出分类结果ROC函数\"\"\"\n","        train_mae=self.test(criterion=nn.L1Loss(),loader=self.trainloader)\n","        train_mse=self.test(criterion=nn.MSELoss(),loader=self.trainloader)\n","        train_r2=self.test(criterion=r2_loss,loader=self.trainloader)\n","        test_mae=self.test(criterion=nn.L1Loss(),loader=self.testloader)\n","        test_mse=self.test(criterion=nn.MSELoss(),loader=self.testloader)\n","        test_r2=self.test(criterion=r2_loss,loader=self.testloader)\n","        print(\"=\"*60)    \n","        print(\"train数据集上模型精度指标(MAE,MSE,R2):\",[train_mae,train_mse,train_r2])\n","        print(\"test数据集上模型精度指标(MAE,MSE,R2):\",[test_mae,test_mse,test_r2])\n","        print(\"=\"*60)\n","    def train(self,criterion,epoch,loader):\n","        self.clf.train()\n","        for _ in range(epoch):\n","            running_loss=0\n","            for x,label in loader:\n","                self.optimizer.zero_grad()\n","                pred=self.clf(x)\n","                loss=criterion(pred,label)\n","                loss.backward()\n","                self.optimizer.step()\n","                running_loss+=loss.item()\n","        return running_loss\n","    def test(self,criterion,loader):\n","        self.clf.eval()\n","        total_loss=0\n","        total_size=0\n","        with torch.no_grad():\n","            for x,label in loader:\n","                output=self.clf(x)\n","                # if criterion==r2_loss:\n","                temp=criterion(output,label).item()*x.shape[0]\n","                total_size+=x.shape[0]\n","                # else:\n","                # temp=criterion(output,label).item()\n","                total_loss+=temp\n","            # if criterion==r2_loss:\n","            return total_loss/total_size\n","            # else:\n","                # return total_loss\n","    def objective(self,params):\n","        self.clf=MyDNN(num_features=self.X_train.shape[1],hidden1=params[\"hidden1\"],hidden2=params[\"hidden2\"])\n","        cv5_index=[0,len(self.y_train)//5,2*len(self.y_train)//5,3*len(self.y_train)//5,4*len(self.y_train)//5,len(self.y_train)-1]\n","        res=0\n","        for i,index in enumerate(cv5_index[:-1]):\n","            self.trainset=MyDataset(self.X_train[[j for j in np.arange(len(self.y_train)) if j<index or j>cv5_index[i+1]], :],\n","                                    self.y_train[[j for j in np.arange(len(self.y_train)) if j<index or j>cv5_index[i+1]]])\n","            self.trainloader=torch.utils.data.DataLoader(self.trainset,batch_size=params[\"batch_size\"],shuffle=True)\n","            # 这里的testset只是名字，其实是validset\n","            self.testset=MyDataset(self.X_train[index:cv5_index[i+1],:],self.y_train[index:cv5_index[i+1]])\n","            self.testloader=torch.utils.data.DataLoader(self.testset,batch_size=params[\"batch_size\"],shuffle=True)\n","            self.optimizer=optim.Adam(self.clf.parameters(),lr=params[\"lr\"])\n","            self.train(criterion=nn.MSELoss(),epoch=params[\"epoch\"],loader=self.trainloader)\n","            res+=self.test(criterion=r2_loss,loader=self.testloader)*len(self.y_train[index:cv5_index[i+1]])\n","        return -res/len(self.y_train)\n","    def HyperoptTrain(self,max_evals=50):\n","        \"\"\"使用tpe.suggest寻找最优参数\"\"\"\n","        trials=Trials()\n","        best_params=fmin(fn=self.objective,space=self.params,\n","                         algo=tpe.suggest,max_evals=max_evals,trials=trials)\n","        best_params=space_eval(self.params, best_params)\n","        print(\"best params:\\n\",best_params)\n","        self.clf=MyDNN(num_features=self.X_train.shape[1],hidden1=best_params[\"hidden1\"],hidden2=best_params[\"hidden2\"])\n","        self.set=MyDataset(self.X_train,self.y_train)\n","        self.trainset=MyDataset(self.X_train,self.y_train)\n","        self.testset=MyDataset(self.X_test,self.y_test)\n","        self.trainloader=torch.utils.data.DataLoader(self.trainset,batch_size=best_params[\"batch_size\"],shuffle=True)\n","        self.testloader=torch.utils.data.DataLoader(self.testset,batch_size=best_params[\"batch_size\"],shuffle=True)\n","        self.loader=torch.utils.data.DataLoader(self.set,batch_size=best_params[\"batch_size\"],shuffle=True)\n","        self.optimizer=optim.Adam(self.clf.parameters(),lr=best_params[\"lr\"])\n","        self.train(criterion=nn.MSELoss(),epoch=best_params[\"epoch\"],loader=self.loader)\n","        return self.clf\n","    def headquarter(self,model_name):\n","        \"\"\"中心调度器，完成从模型训练直到模型报告的所有工作\"\"\"\n","        self.clf=self.HyperoptTrain()\n","        print(model_name,\"模型\",\"训练完成，下面是模型报告：\")\n","        self.Report()\n","        return self.clf\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" 16%|█▌        | 8/50 [09:19<45:42, 65.29s/trial, best loss: -0.13489427578295787]  "]}],"source":["params={\n","    \"batch_size\":hp.choice(\"batch_size\",[500,1000,5000,10000]),\n","    \"epoch\":hp.choice(\"epoch\",np.arange(1,100)),\n","    \"hidden1\":hp.choice(\"hidden1\",np.arange(1,len(X_columns))),\n","    \"hidden2\":hp.choice(\"hidden2\",np.arange(1,len(X_columns))),\n","    \"lr\":hp.choice(\"lr\",[1e-5,1e-4,4e-4,1e-3])\n","}\n","model=Machine(params)\n","clf=model.headquarter(\"Deeplearning model\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.11 ('geopy37')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"966c5bd4e3114327e10ffeb3859fa093c8274e632ab7040ddc3eb7b4ed5aa468"}}},"nbformat":4,"nbformat_minor":2}
